{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fXCWFAL-GqKU",
        "outputId": "b7652724-4ab3-411b-c717-971b3034c37f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.53.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.22.4)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (3.8.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (67.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (4.5.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (16.0.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (0.32.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (23.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.1) (1.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.40.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.17.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.27.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\n",
            "Installing collected packages: keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.0\n",
            "    Uninstalling tensorboard-2.12.0:\n",
            "      Successfully uninstalled tensorboard-2.12.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed flatbuffers-1.12 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.9.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWlRLQ0odJI7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt update\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctmnmC3IdLh5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # Run this cell to mount your drive (you will be prompted to sign in)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3jPi1sUdO-Y",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create the kaggle directory and \n",
        "\n",
        "# (NOTE: Do NOT run this cell more than once unless restarting kernel)\n",
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slTInmcBdRT1",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1582dc6d-e791-457a-d4d2-c1b44de30dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Read the uploaded kaggle.json file\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THFT16lDdTlA",
        "outputId": "680235bc-9ed6-4229-bb27-9c20c7b66563",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Traceback (most recent call last):',\n",
              " '  File \"/usr/local/bin/kaggle\", line 5, in <module>',\n",
              " '    from kaggle.cli import main',\n",
              " '  File \"/usr/local/lib/python3.9/dist-packages/kaggle/__init__.py\", line 23, in <module>',\n",
              " '    api.authenticate()',\n",
              " '  File \"/usr/local/lib/python3.9/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate',\n",
              " \"    raise IOError('Could not find {}. Make sure it\\\\'s located in'\",\n",
              " \"OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Download dataset\n",
        "!!kaggle competitions download -c cassava-leaf-disease-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkb_TM0XdxzZ",
        "outputId": "da950778-892f-4124-eb1b-e25dca61365c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open cassava-leaf-disease-classification.zip, cassava-leaf-disease-classification.zip.zip or cassava-leaf-disease-classification.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# Unzip folder in Colab content folder\n",
        "!unzip cassava-leaf-disease-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgKT1n_7GwLQ",
        "outputId": "72078032-89bd-481e-882e-df04f7e56394",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modules loaded\n"
          ]
        }
      ],
      "source": [
        "import glob, random, os, warnings\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "import itertools\n",
        "\n",
        "# import data handling tools\n",
        "# import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# import Deep learning Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('modules loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g339wsECeTi4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed = 0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "seed_everything()\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBLMVFomJCLm"
      },
      "outputs": [],
      "source": [
        "#Data clean up reference: https://www.kaggle.com/code/abdallahwagih/cassava-leaf-diseases-detection-competition#Model-Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK0ntB-zG13v",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def define_paths(data_dir, csv_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    \n",
        "    df = pd.read_csv(csv_dir)\n",
        "    folds = os.listdir(data_dir)\n",
        "    \n",
        "    for file, i in zip(sorted(folds), df['label']):\n",
        "            fpath = os.path.join(data_dir, file)\n",
        "            filepaths.append(fpath)\n",
        "            if i == 0:    \n",
        "                labels.append('Cassava Bacterial Blight (CBB)')\n",
        "            elif i == 1:\n",
        "                labels.append('Cassava Brown Streak Disease (CBSD)')\n",
        "            elif i == 2:\n",
        "                labels.append('Cassava Green Mottle (CGM)')\n",
        "            elif i == 3:\n",
        "                labels.append('Cassava Mosaic Disease (CMD)')\n",
        "            elif i == 4:\n",
        "                labels.append('Healthy')\n",
        "\n",
        "    return filepaths, labels\n",
        "\n",
        "\n",
        "# Concatenate data paths with labels into one dataframe ( to later be fitted into the model )\n",
        "def define_df(files, classes):\n",
        "    Fseries = pd.Series(files, name= 'filepaths')\n",
        "    Lseries = pd.Series(classes, name='labels')\n",
        "    return pd.concat([Fseries, Lseries], axis= 1)\n",
        "\n",
        "def create_df(tr_dir, csv_dir):\n",
        "    # train and valid dataframe\n",
        "    files, classes = define_paths(tr_dir, csv_dir)\n",
        "    df = define_df(files, classes)\n",
        "    strat = df['labels']\n",
        "    train_df, valid_df = train_test_split(df, train_size= 0.8, shuffle= True, random_state= 123, stratify= strat)\n",
        "\n",
        "    return train_df, valid_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJZhASgII2sF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def create_gens(train_df, valid_df, batch_size):\n",
        "    '''\n",
        "    This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n",
        "    Image data generator converts images into tensors. '''\n",
        "\n",
        "    # define model parameters\n",
        "    img_size = (224, 224)\n",
        "    channels = 3 # either BGR or Grayscale\n",
        "    color = 'rgb'\n",
        "    img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "    # This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n",
        "    def scalar(img):\n",
        "        return img\n",
        "\n",
        "    # without augmentation\n",
        "    # tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n",
        "\n",
        "    # with data augmentation\n",
        "    tr_gen = ImageDataGenerator(\n",
        "      preprocessing_function=scalar,\n",
        "      horizontal_flip=True,\n",
        "      rotation_range=15,  # Rotate images up to 15 degrees\n",
        "      zoom_range=0.1,  # Zoom in/out images up to 20%\n",
        "      width_shift_range=0.1,  # Shift images horizontally up to 20% of the width\n",
        "      height_shift_range=0.1,  # Shift images vertically up to 20% of the height\n",
        "      shear_range=0.2,\n",
        "      fill_mode='nearest',\n",
        "      channel_shift_range=50\n",
        "    )\n",
        "    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "\n",
        "    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= color, shuffle= True, batch_size= batch_size)\n",
        "\n",
        "    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= color, shuffle= True, batch_size= batch_size)\n",
        "\n",
        "    return train_gen, valid_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI7qD_mOI6dL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def trim (df, max_size, min_size, column):\n",
        "    df = df.copy()\n",
        "    original_class_count = len(list(df[column].unique()))\n",
        "    print ('Original Number of classes in dataframe: ', original_class_count)\n",
        "    \n",
        "    sample_list = [] \n",
        "    groups = df.groupby(column)\n",
        "    \n",
        "    for label in df[column].unique():        \n",
        "        group = groups.get_group(label)\n",
        "        sample_count = len(group)     \n",
        "        if sample_count > max_size :\n",
        "            strat = group[column]\n",
        "            samples, _ = train_test_split(group, train_size= max_size, shuffle= True, \n",
        "                                          random_state= 123, stratify= strat)            \n",
        "            sample_list.append(samples)\n",
        "      \n",
        "        elif sample_count >= min_size:\n",
        "            sample_list.append(group)\n",
        "    \n",
        "    df = pd.concat(sample_list, axis= 0).reset_index(drop= True)\n",
        "    final_class_count = len(list(df[column].unique())) \n",
        "    if final_class_count != original_class_count:\n",
        "        print ('*** WARNING***  dataframe has a reduced number of classes' )\n",
        "    balance = list(df[column].value_counts())\n",
        "    print (balance)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o09Xn2Z9JHwK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def show_images(gen):\n",
        "    '''\n",
        "    This function take the data generator and show sample of the images\n",
        "    '''\n",
        "\n",
        "    # return classes , images to be displayed\n",
        "    g_dict = gen.class_indices        # defines dictionary {'class': index}\n",
        "    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes), classes names : string\n",
        "    images, labels = next(gen)        # get a batch size samples from the generator\n",
        "\n",
        "    # calculate number of displayed samples\n",
        "    length = len(labels)        # length of batch size\n",
        "    sample = min(length, 25)    # check if sample less than 25 images\n",
        "\n",
        "    plt.figure(figsize= (20, 20))\n",
        "\n",
        "    # for i in range(sample):\n",
        "    #     plt.subplot(5, 5, i + 1)\n",
        "    #     image = images[i] / 255       # scales data to range (0 - 255)\n",
        "    #     plt.imshow(image)\n",
        "    #     index = np.argmax(labels[i])  # get image index\n",
        "    #     class_name = classes[index]   # get class of image\n",
        "    #     plt.title(class_name, color= 'blue', fontsize= 12)\n",
        "    #     plt.axis('off')\n",
        "    for i in range(25):  # Display 25 augmented images\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        images, labels = next(gen)    # get a batch of samples from the generator\n",
        "        image = images[0] / 255        # scales data to range (0 - 255)\n",
        "        plt.imshow(image)\n",
        "        index = np.argmax(labels[0])  # get image index\n",
        "        class_name = classes[index]   # get class of image\n",
        "        plt.title(class_name, color='blue', fontsize=12)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anZJj7ODJKdY"
      },
      "outputs": [],
      "source": [
        "# This seems redundant\n",
        "# def create_gens(train_df, valid_df, batch_size):\n",
        "#     '''\n",
        "#     This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n",
        "#     Image data generator converts images into tensors. '''\n",
        "\n",
        "#     # define model parameters\n",
        "#     img_size = (224, 224)\n",
        "#     channels = 3 # either BGR or Grayscale\n",
        "#     color = 'rgb'\n",
        "#     img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "#     # This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n",
        "#     def scalar(img):\n",
        "#         return img\n",
        "\n",
        "#     tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n",
        "#     ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "\n",
        "#     train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "#                                         color_mode= color, shuffle= True, batch_size= batch_size)\n",
        "\n",
        "#     valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "#                                         color_mode= color, shuffle= True, batch_size= batch_size)\n",
        "\n",
        "#     return train_gen, valid_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkkpzLaXJVOo",
        "outputId": "a858695f-41b9-4fa0-f341-61504e2f83f1",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Number of classes in dataframe:  5\n",
            "[2000, 2000, 1909, 1751, 870]\n",
            "Found 8530 validated image filenames belonging to 5 classes.\n",
            "Found 4280 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "n_classes = 5\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/cassava-leaf-disease-classification/train_images'\n",
        "csv_dir = '/content/drive/MyDrive/cassava-leaf-disease-classification/train.csv'\n",
        "\n",
        "# Get splitted data\n",
        "train_df, valid_df = create_df(train_dir, csv_dir)\n",
        "train_df = trim(train_df, max_size = 2000, min_size = 1, column='labels')\n",
        "\n",
        "# Print out the number of samples per class\n",
        "# class_counts = train_df['labels'].value_counts()\n",
        "# print(class_counts)\n",
        "\n",
        "# Get Generators\n",
        "train_gen, valid_gen = create_gens(train_df, valid_df, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "58PTNoKAcwdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69912f40-25a2-4fcb-f9ee-a1ab04b156d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Z4mCde6zezwz",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1b1c54-c223-4a3a-9f77-3516f416b927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# Generator for test set\n",
        "test_dir = '/content/drive/MyDrive/cassava-leaf-disease-classification/test_images'\n",
        "test_gen = tf.keras.utils.image_dataset_from_directory(test_dir, labels=None, label_mode=None, color_mode='rgb',\n",
        "                                                        image_size=(224,224), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fecsBfWgUefx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#pd.DataFrame(train_df)\n",
        "\n",
        "show_images(train_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb7C3mApKxXk"
      },
      "outputs": [],
      "source": [
        "# #run this once and then comment out \n",
        "\n",
        "# from google.colab import files\n",
        "# train_df.to_csv('train_df.csv') \n",
        "# files.download('train_df.csv')\n",
        "\n",
        "# valid_df.to_csv('valid_df.csv') \n",
        "# files.download('valid_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs-XGSeLfHEL"
      },
      "source": [
        "## Vision Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUfrdk8rfLuT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "num_epochs = 1\n",
        "\n",
        "patch_size = 7  # Size of the patches to be extract from the input images\n",
        "num_patches = (224 // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [56, 28]  # Size of the dense layers of the final classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6hpgmI2fExw",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Building Multilayer Perceptron (MLP)\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = L.Dense(units, activation = tf.nn.gelu)(x)\n",
        "        x = L.Dropout(dropout_rate)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5gulrjkfar8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Patch Creation Layer\n",
        "class Patches(L.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images = images,\n",
        "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
        "            strides = [1, self.patch_size, self.patch_size, 1],\n",
        "            rates = [1, 1, 1, 1],\n",
        "            padding = 'VALID',\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg4enLcHfu-0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Sample image patches visualization\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "x = train_gen.next()\n",
        "image = x[0][0]\n",
        "\n",
        "plt.imshow(image.astype('uint8'))\n",
        "plt.axis('off')\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size = (image_size, image_size)\n",
        ")\n",
        "\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f'Image size: {image_size} X {image_size}')\n",
        "print(f'Patch size: {patch_size} X {patch_size}')\n",
        "print(f'Patches per image: {patches.shape[1]}')\n",
        "print(f'Elements per patch: {patches.shape[-1]}')\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype('uint8'))\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IswnA32wf2KD",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Patch Encoding Layer\n",
        "\n",
        "# The PatchEncoder layer will linearly transform a patch by projecting it into a vector of size projection_dim. \n",
        "# In addition, it adds a learnable position embedding to the projected vector.\n",
        "class PatchEncoder(L.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = L.Dense(units = projection_dim)\n",
        "        self.position_embedding = L.Embedding(\n",
        "            input_dim = num_patches, output_dim = projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_G7vR6pf-ut",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Building ViT model\n",
        "def vision_transformer():\n",
        "    inputs = L.Input(shape = (image_size, image_size, 3))\n",
        "    \n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(inputs)\n",
        "    \n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        \n",
        "        # Layer normalization 1.\n",
        "        x1 = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
        "        \n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = L.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim = projection_dim, dropout = 0.1\n",
        "        )(x1, x1)\n",
        "        \n",
        "        # Skip connection 1.\n",
        "        x2 = L.Add()([attention_output, encoded_patches])\n",
        "        \n",
        "        # Layer normalization 2.\n",
        "        x3 = L.LayerNormalization(epsilon = 1e-6)(x2)\n",
        "        \n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units = transformer_units, dropout_rate = 0.1)\n",
        "        \n",
        "        # Skip connection 2.\n",
        "        encoded_patches = L.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
        "    representation = L.Flatten()(representation)\n",
        "    representation = L.Dropout(0.5)(representation)\n",
        "    \n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units = mlp_head_units, dropout_rate = 0.5)\n",
        "    \n",
        "    # Classify outputs.\n",
        "    logits = L.Dense(n_classes)(features)\n",
        "    \n",
        "    # Create the model.\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = logits)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4CgXiNogRKX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "decay_steps = train_gen.n // train_gen.batch_size\n",
        "initial_learning_rate = learning_rate\n",
        "\n",
        "lr_decayed_fn = tf.keras.experimental.CosineDecay(initial_learning_rate, decay_steps)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decayed_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMdWmpt_gRtB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "image_size = 224\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "\n",
        "model = vision_transformer()\n",
        "    \n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.1), \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
        "STEP_SIZE_VALID = valid_gen.n // valid_gen.batch_size\n",
        "\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
        "                                                 min_delta = 1e-4,\n",
        "                                                 patience = 5,\n",
        "                                                 mode = 'max',\n",
        "                                                 restore_best_weights = True,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath = './model.hdf5',\n",
        "                                                  monitor = 'val_accuracy', \n",
        "                                                  verbose = 1, \n",
        "                                                  save_best_only = True,\n",
        "                                                  save_weights_only = True,\n",
        "                                                  mode = 'max')\n",
        "\n",
        "callbacks = [earlystopping, lr_scheduler, checkpointer]\n",
        "\n",
        "model.fit(x = train_gen,\n",
        "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "          validation_data = valid_gen,\n",
        "          validation_steps = STEP_SIZE_VALID,\n",
        "          epochs = num_epochs,\n",
        "          callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wckSECxVgYPn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Results\n",
        "print('Training results')\n",
        "model.evaluate(train_gen)\n",
        "\n",
        "print('Validation results')\n",
        "model.evaluate(valid_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50"
      ],
      "metadata": {
        "id": "iQVFkfW4dut1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_resnet50_model(input_shape, num_classes):\n",
        "    # Load pre-trained ResNet50 without the top layer (include_top=False)\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Add custom layers for classification\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create the final model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the input shape and number of classes for the Cassava Leaf Disease dataset\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 5\n",
        "\n",
        "# Create the ResNet50 model\n",
        "resnet50_model = create_resnet50_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "resnet50_model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "FZ_FEFjIdzQV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
        "STEP_SIZE_VALID = valid_gen.n // valid_gen.batch_size"
      ],
      "metadata": {
        "id": "zZfq-z65fbnD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the data \n",
        "\n",
        "resnet50_model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch= STEP_SIZE_TRAIN,\n",
        "    epochs=10,\n",
        "    validation_data=valid_gen\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "q3dH3TBefLZo",
        "outputId": "7424c49a-fafe-46ac-a874-7f55c6614645"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9e2c252f7c45>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m resnet50_model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training results')\n",
        "resnet50_model.evaluate(train_gen)\n",
        "\n",
        "print('Validation results')\n",
        "resnet50_model.evaluate(valid_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlD7fy6MfvMw",
        "outputId": "aef53ca4-4306-41d7-8484-95431ea5b64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results\n",
            "  1/134 [..............................] - ETA: 39:50 - loss: 1.9417 - accuracy: 0.2031"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "conda_amazonei_pytorch_latest_p37",
      "language": "python",
      "name": "conda_amazonei_pytorch_latest_p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}